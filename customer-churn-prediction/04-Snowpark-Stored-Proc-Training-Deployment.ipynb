{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74fa8f0e",
   "metadata": {},
   "source": [
    "# Customer churn analysis\n",
    "\n",
    "\n",
    "# Machine Learning Pipeline\n",
    "\n",
    "In the following notebooks, we will go through the implementation of each one of the steps in the Machine Learning Pipeline. \n",
    "\n",
    "We will discuss:\n",
    "\n",
    "1. Data Preparation and Analysis\n",
    "2. **Feature Engineering**\n",
    "3. **Feature Selection**\n",
    "4. **Model Training**\n",
    "5. **Obtaining Predictions / Scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7750a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.types import *\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from snowflake.snowpark.functions import udf\n",
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# to save the trained scaler class\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb1d0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 7, 0)\n",
      "[Row(CURRENT_WAREHOUSE()='LAB_S_WH', CURRENT_DATABASE()='SNOWPARK_QUICKSTART', CURRENT_SCHEMA()='TELCO')]\n"
     ]
    }
   ],
   "source": [
    "#Snowflake connection info\n",
    "from config import snowflake_conn_prop\n",
    "from snowflake.snowpark import version\n",
    "print(version.VERSION)\n",
    "\n",
    "session = Session.builder.configs(snowflake_conn_prop).create()\n",
    "print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5be4ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 781 ms, sys: 73.8 ms, total: 855 ms\n",
      "Wall time: 3.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw = session.table('TRAIN_DATASET').sample(n = 40000)\n",
    "data = raw.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81258f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22f4f5d",
   "metadata": {},
   "source": [
    "# Separate dataset into train and test\n",
    "\n",
    "It is important to separate our data intro training and testing set. \n",
    "\n",
    "When we engineer features, some techniques learn parameters from data. It is important to learn these parameters only from the train set. This is to avoid over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d4e217",
   "metadata": {},
   "source": [
    "# Snowflake Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80374d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(status='MODELS already exists, statement succeeded.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Stage\n",
    "\n",
    "query = \"create stage if not exists models\" +\\\n",
    "        \" directory = (enable = true)\" +\\\n",
    "        \" copy_options = (on_error='skip_file')\"\n",
    "        \n",
    "session.sql(query).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4db924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stored Proc\n",
    "\n",
    "# setup pipeline\n",
    "\n",
    "# essential libraries\n",
    "\n",
    "from snowflake.snowpark.functions import sproc\n",
    "import snowflake.snowpark\n",
    "import json\n",
    "import cachetools\n",
    "import io\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#transformations\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "session.add_packages('snowflake-snowpark-python', 'scikit-learn', 'pandas', 'numpy', 'joblib', 'cachetools')\n",
    "\n",
    "def save_file(session, model, path):\n",
    "  input_stream = io.BytesIO()\n",
    "  joblib.dump(model, input_stream)\n",
    "  session._conn._cursor.upload_stream(input_stream, path)\n",
    "  return \"successfully created file: \" + path\n",
    "\n",
    "\n",
    "def train_model(session: snowflake.snowpark.Session) -> float:\n",
    "    snowdf = session.table(\"TRAIN_DATASET\")\n",
    "    # split the train and test set\n",
    "    snowdf_train, snowdf_test = snowdf.random_split([0.8, 0.2], seed=82) # use seed to make the split repeatable\n",
    "    \n",
    "\n",
    "    # save the train and test sets as time stamped tables in Snowflake \n",
    "    snowdf_train.write.mode(\"overwrite\").save_as_table(\"CHURN_TRAIN\")\n",
    "    snowdf_test.write.mode(\"overwrite\").save_as_table(\"CHURN_TEST\")\n",
    "    \n",
    "       \n",
    "    churn_train = snowdf_train.drop(\"CHURNVALUE\",\"CUSTOMERID\").to_pandas() # drop labels for training set\n",
    "    churn_train_labels = snowdf_train.select(\"CHURNVALUE\").to_pandas()\n",
    "    \n",
    "    churn_test = snowdf_test.drop(\"CHURNVALUE\",\"CUSTOMERID\").to_pandas()\n",
    "    churn_test_labels = snowdf_test.select(\"CHURNVALUE\").to_pandas()\n",
    "    \n",
    "    cat_vars = ['GENDER', 'SENIORCITIZEN', 'PARTNER', 'DEPENDENTS', 'PHONESERVICE', 'MULTIPLELINES', 'INTERNETSERVICE',\n",
    "            'ONLINESECURITY', 'ONLINEBACKUP', 'DEVICEPROTECTION', 'TECHSUPPORT', 'STREAMINGTV', 'STREAMINGMOVIES',\n",
    "            'CONTRACT', 'PAPERLESSBILLING', 'PAYMENTMETHOD']\n",
    "\n",
    "    # we will capture those of type numerical from previous notebook\n",
    "    num_vars = [ 'TENUREMONTHS', 'MONTHLYCHARGES', 'TOTALCHARGES']\n",
    "    \n",
    "    \n",
    "    # Model Pipeline\n",
    "    num_pipe = Pipeline([\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "            ('scaler', MinMaxScaler()),\n",
    "        ])\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "            ('num_transform', num_pipe, num_vars),\n",
    "            ('ordinalEncoding',OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_vars)\n",
    "        ])\n",
    "    \n",
    "    clf = make_pipeline(RandomForestClassifier(random_state=0, n_jobs=-1))\n",
    "    \n",
    "    model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', clf),\n",
    "        ])\n",
    "\n",
    "    # fit the model\n",
    "    model.fit(churn_train, churn_train_labels)\n",
    "    \n",
    "    # save the full pipeline including the model\n",
    "    save_file(session, model, \"@MODELS/churn_model_reg.joblib\")\n",
    "\n",
    "    # predict on the test set and return the root mean squared error (RMSE)\n",
    "    churn_predictions = model.predict(churn_test)\n",
    "    lin_mse = mean_squared_error(churn_test_labels, churn_predictions)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    return lin_rmse\n",
    "\n",
    "# Create an instance of StoredProcedure using the sproc() function\n",
    "train_model_sp = sproc(train_model, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df962f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05438601172561986"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_sp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c40f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cachetools\n",
    "import os\n",
    "from snowflake.snowpark.functions import udf\n",
    "session.add_import(\"@MODELS/churn_model_reg.joblib\")\n",
    "\n",
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "       import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "       if import_dir:\n",
    "              with open(os.path.join(import_dir, filename), 'rb') as file:\n",
    "                     m = joblib.load(file)\n",
    "                     return m\n",
    "\n",
    "cat_vars = ['GENDER', 'SENIORCITIZEN', 'PARTNER', 'DEPENDENTS', 'PHONESERVICE', 'MULTIPLELINES', 'INTERNETSERVICE',\n",
    "            'ONLINESECURITY', 'ONLINEBACKUP', 'DEVICEPROTECTION', 'TECHSUPPORT', 'STREAMINGTV', 'STREAMINGMOVIES',\n",
    "            'CONTRACT', 'PAPERLESSBILLING', 'PAYMENTMETHOD']\n",
    "\n",
    "# we will capture those of type numerical from previous notebook\n",
    "num_vars = [ 'TENUREMONTHS', 'MONTHLYCHARGES', 'TOTALCHARGES']\n",
    "\n",
    "features = cat_vars + num_vars\n",
    "\n",
    "@udf(name='predict_churn_sp',is_permanent = True, stage_location = '@MODELSTAGE', replace=True)\n",
    "def predict_churn_sp(args: list) -> float:\n",
    "    model = read_file('churn_model_reg.joblib') \n",
    "    row = pd.DataFrame([args], columns=features)\n",
    "    return model.predict(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "958c0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = session.table('TRAIN_DATASET').sample(n = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324664c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 ms, sys: 2.4 ms, total: 14.1 ms\n",
      "Wall time: 9.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_df.select(new_df.CUSTOMERID,new_df.CHURNVALUE, \\\n",
    "              F.call_udf(\"predict_churn_sp\", F.array_construct(*features)).alias('PREDICTED_CHURN')) \\\n",
    "        .write.mode('overwrite').saveAsTable('churn_detection_sp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f047ac5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMERID</th>\n",
       "      <th>CHURNVALUE</th>\n",
       "      <th>PREDICTED_CHURN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5387-EOILJ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1931-vmLou</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2433-8SKsn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4697-rVNqe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4896-kMcAF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>5993-k1Ed8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>7206-OwbN2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1978-CFauk</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>4926-5sIr4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>9647-Z22zn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CUSTOMERID  CHURNVALUE  PREDICTED_CHURN\n",
       "0    5387-EOILJ         0.0              0.0\n",
       "1    1931-vmLou         0.0              0.0\n",
       "2    2433-8SKsn         0.0              0.0\n",
       "3    4697-rVNqe         0.0              0.0\n",
       "4    4896-kMcAF         0.0              0.0\n",
       "..          ...         ...              ...\n",
       "395  5993-k1Ed8         0.0              0.0\n",
       "396  7206-OwbN2         0.0              0.0\n",
       "397  1978-CFauk         1.0              1.0\n",
       "398  4926-5sIr4         0.0              0.0\n",
       "399  9647-Z22zn         1.0              1.0\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.table('churn_detection_sp').toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e18b0f",
   "metadata": {},
   "source": [
    "## if we want to do the prediction using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df775ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "|\"CUSTOMERID\"  |\"CHURNVALUE\"  |\"CHURN_PREDICTION\"  |\n",
      "----------------------------------------------------\n",
      "|5079-nKQop    |0.0           |0.0                 |\n",
      "|5173-SV7pB    |1.0           |1.0                 |\n",
      "|2290-VXBex    |0.0           |0.0                 |\n",
      "|6609-mN9Pj    |0.0           |0.0                 |\n",
      "|5686-nS5El    |0.0           |0.0                 |\n",
      "|8679-XeJg2    |1.0           |1.0                 |\n",
      "|6501-oLL0P    |0.0           |0.0                 |\n",
      "|3876-RSSAT    |0.0           |0.0                 |\n",
      "|3848-Bm4BZ    |0.0           |0.0                 |\n",
      "|6725-cMHN2    |1.0           |1.0                 |\n",
      "----------------------------------------------------\n",
      "\n",
      "CPU times: user 6.03 ms, sys: 1.93 ms, total: 7.96 ms\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "session.sql(' select customerid,churnvalue, \\\n",
    "            predict_churn_sp(ARRAY_CONSTRUCT( \\\n",
    "                                    GENDER, \\\n",
    "                                    SENIORCITIZEN, \\\n",
    "                                    PARTNER, \\\n",
    "                                    DEPENDENTS, \\\n",
    "                                    PHONESERVICE, \\\n",
    "                                    MULTIPLELINES,  \\\n",
    "                                    INTERNETSERVICE,  \\\n",
    "                                    ONLINESECURITY,  \\\n",
    "                                    ONLINEBACKUP, \\\n",
    "                                    DEVICEPROTECTION,  \\\n",
    "                                    TECHSUPPORT,  \\\n",
    "                                    STREAMINGTV,  \\\n",
    "                                    STREAMINGMOVIES, \\\n",
    "                                    CONTRACT,  \\\n",
    "                                    PAPERLESSBILLING,  \\\n",
    "                                    PAYMENTMETHOD,  \\\n",
    "                                    TENUREMONTHS, \\\n",
    "                                    MONTHLYCHARGES,  \\\n",
    "                                    TOTALCHARGES)) as Churn_prediction \\\n",
    "                                    from train_dataset sample (10 rows)').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42769e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3def27e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "getting_started_snowpark_python",
   "language": "python",
   "name": "getting_started_snowpark_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
